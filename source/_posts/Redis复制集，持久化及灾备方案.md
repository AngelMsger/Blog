---
title: Redis复制集，持久化及灾备方案
date: 2018-01-30 20:27:10
tags:
- Redis
- HA
- Replication
- Database
- DevOps
categories:
- Database
thumbnail: "/images/Redis复制集，持久化及灾备方案.jpg"
---
本文给出一些Redis关于复制集的作用，简单原理和搭建方式，数据持久化，以及常见灾备问题与解决方案。

# Redis复制集

## 复制集的概念与简单原理
首先要知道Redis**复制集(Replication)**和**集群(Cluster)**并不是一个概念，复制集的从节点不断从主节点同步数据，主要目的是平时可以分担一些主节点的读压力，即读写分离。当主节点实例挂掉之后从节点因为含有主节点的几乎所有数据，因此能够快速接替主节点对外服务，这和MongoDB的复制集作用是很相似的。而集群则是几乎完全不同的东西，可以用来做切片，不在本文讨论内容之内。

## Redis复制集的特点
1. Redis主节点可以与多个从节点关联，从节点亦可级联从节点。主从之间采用异步复制。
2. 当网络状况波动时，从节点将以增量的方式重新请求在波动期间未同步的数据。若此行为不能成功，才尝试全量数据同步。
3. 数据同步过程对于主从节点都是非阻塞的。这意味着在数据同步期间，主从节点仍可以对外提供服务。从节点在数据同步完成之前将使用旧数据集进行服务，在数据同步完成后将进行新旧数据的切换，对于非常大的数据集，这可能造成长达数秒的阻塞。
4. 主节点可以配置关闭持久化以提升性能，并在从节点开启持久化如AOF(后文详述)。但是这事一个**需要谨慎考虑**的事情，风险在于主节点在关闭持久化后，Redis实例一旦挂掉重启，将含有一个空数据集，而从节点会同步这一事实，整个复制集会被清空。正由于此原因，通常不建议关闭主节点的持久化。但有时我们不得不这样做，因为主节点可能运行在一个带有非常慢IO速度磁盘的主机上。那此时我们必须阻止Redis自动重启，比如修改Supervisor或Docker的相关策略。

## Redis复制集的简单原理
每一个Redis主节点包含一个复制集ID和偏移量，复制集ID是一个很长的伪随机串，我们可以认为不会重复。偏移量是一个会随数据变化而增长的量，标识变化过程以便于从节点增量同步数据。即使没有从节点连接到主节点上，偏移量也会变化。通过复制集ID和偏移量就可以拿到数据集的某一版本。
当从节点进入复制集与主节点相连时，从节点会使用PSYNC命令(老版本会使用SYNC，但SYNC不支持增量同步，新版本仅出于兼容性考虑保留了这条命令，但我们应当向PSYNC迁移)向主节点发送复制集ID或偏移量。主节点根据拿到的复制集ID或偏移量向从节点发送增量数据 (即仅包含该偏移量之后变化的数据)。如果主节点检测到缓冲区中已经没有足够的日志以支持增量更新 (可能因为该偏移量太过久远)，或复制集ID不可识别，则会要求从节点全量更新。
全量更新的细节是，主节点启动一个后台进程保存当前数据集的快照RDB(后文详述)，与此同时开始缓存所有来自客户端的新请求。当RDB快照文件写入完成时，主节点将RDB快照文件连同之后缓存的所有请求指令发往从节点，从节点加载RDB快照文件并应用指令，完成全量同步。
当主节点同时收到多个从节点的同步请求时，上述过程仅会做一次，而得到的RDB快照文件和缓存的指令将发送给所有请求的从节点。全量数据同步会把数据写到磁盘上，

## 配置
redis.conf中包含了Redis实例的配置，并且有非常详细的说明，我这里只提几个与本文相关的。
配置复制集比较简单，只需在从节点配置中加入`slaveof 192.168.151.198 6379`即可，当然IP和端口要换成主节点对应的配置。也可以通过Redis-Cli输入`SLAVEOF ...`动态配置。如果你的主节点配置了密码认证，则在配置文件中加入`masterauth ...`或使用`CONFIG SET MASTERAUTH ...`指令。
redis.conf中还有一些其他选项，比如repl-diskless-sync-delay可以在收到更新请求时延时以等待是否有更多的从节点数据同步请求。
同样地，如果你有一个读写速度很慢的磁盘，这会非常耗时。Redis在2.8.18之后的版本支持无盘快照，可以在redis.conf中修改repl-diskless-sync。

## 从节点的可读性和可写性
虽然我在第一段中提到Redis和MongoDB的复制集有些相似，但只是为了熟悉MongoDB的童鞋快速了解一下Redis复制集是干什么用的。实际上Redis和MongoDB的复制集还是有很大不同的，比如在MongoDB中，从节点是绝对不可写的。而Redis中没有这个说法，虽然从节点默认设置为不可写，但这一设置也可以被修改。Redis设计者认为在Redis的应用场景中，存在一些情况需要从节点具有可写性，比如对于一些缓慢的排序操作，我们临时保留其结果以备多次访问。
前文说过，Redis支持级联式的字节点，即A->B->C，那B节点若配置为可写，C节点的数据是什么样的呢？答案是与A相同，即**可写从节点中的临时修改部分不会被传递至级联节点**。
还有一点需要特别注意，Redis在4.0版本前，如果从节点可写，则他不支持配置了生存时间 (TTL) 的键值，这些键值写入后会丢失并占用内存，这会出现问题。在4.0版本后的Redis修复了这一问题。
即使配置为只读的从节点，直接暴露在不受信任的客户端之下也并不安全，因为对于虽然数据设置为只读，但一些调试接口可能却是开放的，这一点需要留意。

# 数据持久化方式
Redis数据持久化主要有2种方式：**RDB**和**AOF**。

## RDB：即数据库定期备份快照
定期备份快照的优势在于性能较高，Redis只需定期fork子进程执行备份工作，快照文件还可以转储至数据盘或云服务提供商。在Redis重新启动时，快照文件也可以更快的进行导入。RDB的备份周期通常比AOF更长，所以如果Redis实例挂掉的话你可能会丢失最近写入的全部数据。并且如果数据集非常大，fork可能会使Redis短暂停止服务。

## AOF：针对每秒或每个查询记录日志
在这种情况下的优势在于如果Redsi实例挂掉你将只会失去极少数据 (如1s之内)，并且日志以追加的形式写入文件，因此即使遇到磁盘已满这种极端情况，Redis依然能最大程度的保证数据被记录，而对于RDB，即使磁盘仍有空余空间，也可能会因为不足以保存一份完整的快照而丢失本次备份的全部数据。当日志文件过大时，Redis会尝试重写一份日志，不过这是安全的，因为在重写的同时Redis依然会把最新改动附加至原有日志之后，直到新的日志足以描述如何生成当前Redis实例中的全部数据时，Redis才会进行切换，只向新日志追加内容并丢弃旧的日志。为什么重写日志会使日志的体积减小？加入你连续调用100次`INCR foo:bar`，Redis将写入100条让变量foo:bar增加1的日志，如你所知，当恢复数据的时候我们并不必要再次这样做。日志重写从原理来讲，是父进程fork子进程，子进程重写新日志，在重写的过程中，新的键值查询会被追加到旧日志末尾，并同时缓存至内存，直到子进程完成重写，切换日志，再将缓存的数据写入新日志，保证数据的完整性。RDB与AOF并不互斥，你可以同时开启两者。AOF方式存储的日志格式对于操作人员是可读的，你可以方便的导出或修改。

## 配置
1. RDB：在Redis-CLI中输入指令`SAVE 频率 操作阈值`：比如`SAVE 60 1000`代表在键值修改数量大于1000的情况下每60秒备份一次快照。
2. AOF：在配置文件中写入`appendonly yes`。此处值得一提，AOF目前允许选择三种策略，比较好的实践是每秒写入一次，这也是开启AOF后的默认值。其他两个选项分别是always和never，always会记录每次写入。这最安全，但性能不太好，但不太值得，官网的描述是"very very slow"。至于never，就不多提了。

当Redis同时开启RDB和AOF方式时，Redis将优先从AOF日志中恢复数据，因为AOF日志的数据通常更完整。Redis也支持将RDB的快照文件转换为AOF日志，如果你需要，可以去官方文档中找点线索，这和版本有关，就不细说了。

# 灾备解决方案
对于Redis，数据持久化及灾备一定程度上是在说同一件事，因为Redis启动会尝试从持久化文件，也就是前面所述的快照或日志中恢复数据，因此你要做的就是开启一个合适的数据持久化方案，并备份持久化文件。备份这件事你可以放心的写个简单的脚本并交给Linux cron来完成，因为Redis的RDB快照文件完全支持在Redis运行的情况下进行复制，这是由于快照文件在生成后并不会再变化，新的快照文件会以一个临时的文件名存储，并在适当的时候重新命名。

# 参考资料
[Redis Documentation](https://redis.io/documentation)
