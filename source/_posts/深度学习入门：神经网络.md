---
title: 深度学习入门：神经网络
date: 2023-12-02 19:25:24
categories:
  - AI
tags:
  - AI
  - Deep Learning
mathjax: true
thumbnail: "/images/banner/深度学习入门：神经网络.jpg"
typora-root-url: ../../source/
---

# 概述

在[上一篇文章](/深度学习入门：逻辑回归)中, 我们主要介绍了现代人工智能技术的基石 - 神经网络的一些基础理论, 并重点解析了逻辑回归的原理和实现. 本文在此基础之上, 为其扩展隐藏层成为**标准神经网络**, 并讨论此过程中会遇到的问题和解决手段.



# 神经网络

如果我们把逻辑回归视作神经元, 并以其为单元构建计算图, 就可以得到一个网状结构, 我们称其为**神经网络**(Neural Network, NN), 结构如下:

![classification_kiank](/images/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/classification_kiank.png)

我们一般通过**层级结构**描述神经网络, 将除去输入/输出层之外的中间层称为**隐藏层**, 并且在统计层数时忽略输入层, 因此上图就是一个拥有一个隐藏层的两层神经网路. 我们曾在上一篇文章末尾约定过相关符号的含义, 这里不再重复.



# 代码实现

## 数据集

为了更好的展示分类效果的差异, 本文将原始场景替换为二维坐标系下的点分类问题: 以下图的花形样本分布为数据集, 训练一个模型预测任给输入坐标 $(x, y)$ 的颜色:

![数据集](/images/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E6%95%B0%E6%8D%AE%E9%9B%86.png)

样本点的生成逻辑可以参考 Notebook 中的代码, 此处不再展开:

```python
def load_planar_dataset():
  np.random.seed(1)
  m = 400 														# 样本点的数量.
  N = int(m / 2) 											# 每个分类下样本点的数量.
  D = 2 															# 样本维度.
  X = np.zeros((m, D)) 								# 样本坐标矩阵.
  Y = np.zeros((m, 1), dtype='uint8')	# 标签矩阵.
  a = 4																# 花轴数量.
  for j in range(2):
    ix = range(N * j, N * (j + 1))
    t = np.linspace(j * 3.12, (j + 1) * 3.12, N) + np.random.randn(N) * 0.2
    r = a*np.sin(4*t) + np.random.randn(N)*0.2
    X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]
    Y[ix] = j    
  X = X.T
  Y = Y.T
  return X, Y

# 生成数据集.
X, Y = load_planar_dataset()
```

## 逻辑回归

在引入神经网络之前, 我们先通过此前介绍的逻辑回归的方式解决上述问题并作为对照组. 我们在上一篇文章中已经介绍过逻辑回归的原理, 但就像我们通常不需要手写排序算法一样, 逻辑回归这种常见算法也有很多库函数提供了标准实现, 比如 [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html).

```python
clf = sklearn.linear_model.LogisticRegressionCV();
clf.fit(X.T, Y.T.reshape((shape_Y[1],)));
```

打印逻辑回归的决策边界:

![逻辑回归决策边界](/images/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%86%B3%E7%AD%96%E8%BE%B9%E7%95%8C.png)

可以看到, 由于数据集并不是线性可分割的, 因此逻辑回归的效果并不好, 模型准确率只有 47%, 和瞎猜没什么区别.

## 神经网络

# 结语

